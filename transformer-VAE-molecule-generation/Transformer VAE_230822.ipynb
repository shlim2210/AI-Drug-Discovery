{"cells":[{"cell_type":"markdown","metadata":{"id":"pzmehcunUoob"},"source":["# Reference\n","\n","    1. Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules, 2015 ( https://pubs.acs.org/doi/full/10.1021/acscentsci.7b00572 )\n","        ✔ SMILES VAE는 분자를 연속적이고 차별화 가능한 latent space에 매핑하며, 특정 속성(logP, QED, SAS, 생체 활성 등)에 최적화할 수 있음.\n","\n","    2. Self-Referencing Embedded Strings (SELFIES): A 100% robust molecular string representation, 2020 ( https://iopscience.iop.org/article/10.1088/2632-2153/aba947 )\n","        ✔ language model로 분자를 생성할 때, invalid한 분자를 생성할 가능성이 있는 SMILES 표기와 달리, SELIFES 표기를 사용하여 100% valid한 분자 생성을 하도록 함."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26422,"status":"ok","timestamp":1692678895548,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"LysjwN9rOcTM","outputId":"81608002-4338-43ad-a150-d202c573865d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1692678900096,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"hUY7z4V0iEv3","outputId":"a6928579-a3d9-41bb-e16a-36447d1212ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 22 04:34:59 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   58C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19367,"status":"ok","timestamp":1692678919763,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"rhJlQm1NiFfJ","outputId":"4905435c-0e13-4291-cd54-baa70ff45f4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=978e146963093f2fa3033d4ab656a035ddfb499b28d4eb68d869e3c428992f23\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.32 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.8\n","Collecting rdkit\n","  Downloading rdkit-2023.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2023.3.3\n","Collecting selfies\n","  Downloading selfies-2.1.1-py3-none-any.whl (35 kB)\n","Installing collected packages: selfies\n","Successfully installed selfies-2.1.1\n"]}],"source":["!pip install wandb\n","!pip install rdkit\n","!pip install selfies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1692704379321,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"a0JiFDTNiIcZ","outputId":"bb4b0f02-2b34-4bbe-bb12-f3d6032b5ced"},"outputs":[{"output_type":"stream","name":"stdout","text":["Torch ver. : 2.0.1+cu118\n"]}],"source":["import argparse\n","import sys\n","import yaml\n","import json\n","import os\n","import joblib\n","import networkx as nx\n","from tqdm import tqdm\n","from datetime import datetime\n","import time\n","import random\n","import copy\n","from collections import defaultdict\n","import pickle as pkl\n","import re\n","import spacy\n","import codecs\n","import collections.abc\n","collections.Mapping = collections.abc.Mapping\n","\n","from prettytable import PrettyTable\n","import selfies\n","import wandb\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import rdkit\n","import rdkit.Chem as Chem\n","from rdkit.Chem import Draw\n","import rdkit.Chem.AllChem as AllChem\n","from PIL import Image\n","from IPython.core.display import display\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.nn.utils import clip_grad_norm_\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","os.environ['TORCH'] = torch.__version__\n","print(f'Torch ver. : {torch.__version__}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r29B_6s9oazB"},"outputs":[],"source":["ENTITY = 'rossi22'\n","TRAIN_PROJECT = 'TRANS_VAE_SELFIES_TRAIN'\n","SWEEP_PROJECT = 'TRANS_VAE_SELFIES_SWEEP'\n","\n","DEFAULT_PARAMS = {\n","    'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","    'batch_size': 128,\n","    'learning_rate': 0.0002,\n","    'epochs': 500,\n","    'period':5,\n","\n","    'embed_dim': 32,\n","    'latent_dim': 128,\n","    'hidden_dim': 64,\n","    'enc_layers': 4,\n","    'dec_layers': 4,\n","    'enc_heads': 8,\n","    'dec_heads': 8,\n","    'enc_pos_dim': 256,\n","    'dec_pos_dim': 256,\n","    'enc_dropout': 0.1,\n","    'dec_dropout': 0.1,\n","    'pad_idx': 0,\n","    'clip': 0.01,\n","\n","    'use_scheduler': True,\n","    'schd_factor': 0.5,\n","    'schd_patience': 10,\n","    'schd_min_lr': 5e-6,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0KvNYzvvuLG"},"outputs":[],"source":["def load_smiles(file_name, num_mol):\n","    file_pkl = pkl.load(open(file_name, 'rb'))\n","    num_mol = min(len(file_pkl), num_mol)\n","    smi_list = []\n","    selfies_list = []\n","    for i in tqdm(range(num_mol), desc='Reading Data'):\n","        smi = file_pkl[i].strip()\n","        smi_list.append(smi)\n","        selfies_list.append(selfies.encoder(smi))\n","\n","    return smi_list, selfies_list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126452,"status":"ok","timestamp":1692679058143,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"HhGdUeOTW011","outputId":"9fb92c2f-b38e-45da-d660-6aae41f1f132"},"outputs":[{"output_type":"stream","name":"stderr","text":["Reading Data: 100%|██████████| 100000/100000 [00:38<00:00, 2621.99it/s]\n","Reading Data: 100%|██████████| 251637/251637 [01:26<00:00, 2899.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["350867\n"]}],"source":["_, selfies_list = load_smiles('/content/drive/MyDrive/Colab Notebooks/Python/Portfolio/dataset/ZINC_smi.pkl', int(3e5))\n","_, selfies_list2 = load_smiles('/content/drive/MyDrive/Colab Notebooks/Python/Portfolio/dataset/ZINC_smi2.pkl', int(3e5))\n","selfies_list = list(set(selfies_list+selfies_list2))\n","print(len(selfies_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mu3IuvOkBnYY"},"outputs":[],"source":["def dict_tokens(data) :\n","    tokens = {'<pad>': 0, '<sos>': 1, '<eos>': 2, }\n","    max_len = 0\n","    for word in data :\n","        max_len = max(max_len, selfies.len_selfies(word))\n","\n","    selfies_token_list = selfies.get_alphabet_from_selfies(data)\n","    selfies_tokens = {key:i+3 for i, key in enumerate(selfies_token_list)}\n","    tokens.update(selfies_tokens)\n","    selfies_r_tokens = {val:key for (key, val) in tokens.items()}\n","\n","    return max_len+2, tokens, selfies_r_tokens\n","\n","DEFAULT_PARAMS['selfies_max_len'], DEFAULT_PARAMS['selfies_tokens'], DEFAULT_PARAMS['selfies_reverse_tokens'] = dict_tokens(selfies_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85584,"status":"ok","timestamp":1692679150673,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"5Ra_NoTlGCPr","outputId":"34840096-1883-489e-877a-313f028348ac"},"outputs":[{"output_type":"stream","name":"stderr","text":["350867it [01:25, 4095.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[C][C][=C][C][=C][Branch1][#C][C][=Branch1][C][=O][O][C][C][C][N][C][Branch1][C][N][=O][C][=C][Ring1][S][C]\n","tensor([ 1, 15, 15, 37, 15, 37,  3, 35, 15, 16, 15, 34, 29, 15, 15, 15, 41, 15,\n","         3, 15, 41, 34, 15, 37, 38, 36, 15,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0])\n"]}],"source":["def embedding_data(data, max_len=DEFAULT_PARAMS['selfies_max_len'], dict_tokens=DEFAULT_PARAMS['selfies_tokens']) :\n","    emb_data = torch.zeros((len(data), max_len))\n","\n","    for idx1, word in tqdm(enumerate(data)) :\n","        emb_data[idx1][0] = dict_tokens['<sos>']\n","        idx2 = 1\n","        for tok in selfies.split_selfies(word) :\n","            if tok != '.' :\n","                emb_data[idx1][idx2] = dict_tokens[tok]\n","                idx2 +=1\n","        emb_data[idx1][idx2] = dict_tokens['<eos>']\n","\n","    emb_data = emb_data.type(torch.LongTensor)\n","    return emb_data\n","\n","embedded_selfies = embedding_data(selfies_list)\n","\n","print(selfies_list[0])\n","print(embedded_selfies[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3883,"status":"ok","timestamp":1692679155609,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"rYVbXA_hrys6","outputId":"ee57bc95-eb59-41dd-c258-5cabdc2e0cc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["333323 8772 8772\n"]}],"source":["train_size = int(len(selfies_list) * 9.5 // 10)\n","val_size = (len(selfies_list)-train_size)//2\n","\n","def set_seed(seed_value):\n","\n","    torch.manual_seed(seed_value)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","    np.random.seed(seed_value)\n","    random.seed(seed_value)\n","\n","set_seed(52)\n","random.shuffle(embedded_selfies)\n","\n","TRAIN_SET, VAL_SET, TEST_SET = embedded_selfies[:train_size], embedded_selfies[train_size:train_size+val_size], embedded_selfies[train_size+val_size:]\n","print(len(TRAIN_SET), len(VAL_SET), len(TEST_SET))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upV1KGNKCrPo"},"outputs":[],"source":["class MultiHeadAttentionLayer(nn.Module):\n","    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n","        super().__init__()\n","\n","        assert hidden_dim % n_heads == 0\n","\n","        self.hidden_dim = hidden_dim # 임베딩 차원\n","        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n","        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원\n","\n","        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n","        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n","        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n","\n","        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n","\n","    def forward(self, query, key, value, mask = None):\n","\n","        batch_size = query.shape[0]\n","\n","        # query: [batch_size, query_len, hidden_dim]\n","        # key: [batch_size, key_len, hidden_dim]\n","        # value: [batch_size, value_len, hidden_dim]\n","\n","        Q = self.fc_q(query)\n","        K = self.fc_k(key)\n","        V = self.fc_v(value)\n","\n","        # Q: [batch_size, query_len, hidden_dim]\n","        # K: [batch_size, key_len, hidden_dim]\n","        # V: [batch_size, value_len, hidden_dim]\n","\n","        # hidden_dim → n_heads X head_dim 형태로 변형\n","        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n","        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","\n","        # Q: [batch_size, n_heads, query_len, head_dim]\n","        # K: [batch_size, n_heads, key_len, head_dim]\n","        # V: [batch_size, n_heads, value_len, head_dim]\n","\n","        # [1], [2] Attention Energy 계산, scaling\n","        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n","\n","        # energy: [batch_size, n_heads, query_len, key_len]\n","\n","        # [3] 마스크(mask)를 사용하는 경우\n","        if mask is not None:\n","            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n","            energy = energy.masked_fill(mask==0, -1e10)\n","\n","        # [4] 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n","        attention = torch.softmax(energy, dim=-1)\n","        # attention: [batch_size, n_heads, query_len, key_len]\n","\n","        # [5] attention과 Value의 Scaled Dot-Product Attention을 계산\n","        x = torch.matmul(self.dropout(attention), V)\n","        # x: [batch_size, n_heads, query_len, head_dim]\n","        x = x.permute(0, 2, 1, 3).contiguous()\n","        # x: [batch_size, query_len, n_heads, head_dim]\n","        x = x.view(batch_size, -1, self.hidden_dim)\n","        # x: [batch_size, query_len, hidden_dim]\n","        x = self.fc_o(x)\n","        # x: [batch_size, query_len, hidden_dim]\n","        return x, attention\n","\n","class PositionwiseFeedforwardLayer(nn.Module):\n","    def __init__(self, hidden_dim, pos_dim, dropout_ratio):\n","        super().__init__()\n","\n","        self.fc_1 = nn.Linear(hidden_dim, pos_dim)\n","        self.fc_2 = nn.Linear(pos_dim, hidden_dim)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","    def forward(self, x):\n","        # x: [batch_size, seq_len, hidden_dim]\n","        x = self.dropout(torch.relu(self.fc_1(x)))\n","        # x: [batch_size, seq_len, pos_dim]\n","        x = self.fc_2(x)\n","        # x: [batch_size, seq_len, hidden_dim]\n","        return x\n","\n","class GatedSkipConnection(nn.Module):\n","\n","    def __init__(self, in_dim, out_dim):\n","        super(GatedSkipConnection, self).__init__()\n","\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","\n","        self.linear = nn.Linear(in_dim, out_dim, bias=False)\n","        self.linear_coef_in = nn.Linear(out_dim, out_dim)\n","        self.linear_coef_out = nn.Linear(out_dim, out_dim)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, in_x, out_x):\n","        if (self.in_dim != self.out_dim):\n","            in_x = self.linear(in_x)\n","        # z : 0 ~ 1 사이의 값\n","        z = self.gate_coefficient(in_x, out_x)\n","        out = torch.mul(z, out_x) + torch.mul(1.0-z, in_x)\n","        return out\n","\n","    def gate_coefficient(self, in_x, out_x):\n","        x1 = self.linear_coef_in(in_x)\n","        x2 = self.linear_coef_out(out_x)\n","        return self.sigmoid(x1+x2)\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, n_heads, pos_dim, dropout_ratio, device):\n","        super().__init__()\n","\n","        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pos_dim, dropout_ratio)\n","        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","        self.gsc = GatedSkipConnection(hidden_dim, hidden_dim)\n","\n","    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n","    def forward(self, src, src_mask):\n","        # src: [batch_size, src_len, hidden_dim]\n","        # src_mask: [batch_size, src_len]\n","\n","        # self attention\n","        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n","        _src, _ = self.self_attention(src, src, src, src_mask)\n","        # dropout, residual connection and layer norm\n","        src = self.self_attn_layer_norm(self.gsc(src, _src))\n","        # src: [batch_size, src_len, hidden_dim]\n","\n","        # position-wise feedforward\n","        _src = self.positionwise_feedforward(src)\n","        # dropout, residual and layer norm\n","        src = self.ff_layer_norm(self.gsc(src, _src))\n","        # src: [batch_size, src_len, hidden_dim]\n","\n","        return src\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, embed_dim, hidden_dim, latent_dim,  n_layers, n_heads, pos_dim, dropout_ratio, max_len, device):\n","        super().__init__()\n","\n","        self.device = device\n","        self.tok_embedding = nn.Embedding(input_dim, embed_dim)\n","        self.pos_embedding = nn.Embedding(max_len, embed_dim)\n","        self.initial_linear = nn.Linear(embed_dim, hidden_dim)\n","        self.en_layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pos_dim, dropout_ratio, device) for _ in range(n_layers)])\n","        self.dropout = nn.Dropout(dropout_ratio)\n","        self.scale = torch.sqrt(torch.FloatTensor([embed_dim])).to(device)\n","\n","        self.relu = nn.ReLU()\n","        self.mean = nn.Linear(max_len * hidden_dim, latent_dim)\n","        self.log_var = nn.Linear(max_len * hidden_dim, latent_dim)\n","\n","    def forward(self, src, src_mask):\n","\n","        # src: [batch_size, src_len]\n","        # src_mask: [batch_size, src_len]\n","        batch_size = src.shape[0]\n","        src_len = src.shape[1]\n","\n","        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        # pos: [batch_size, src_len]\n","\n","        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n","        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n","        # src: [batch_size, src_len, embed_dim]\n","        src = self.initial_linear(src)\n","        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n","        for layer in self.en_layers:\n","            src = layer(src, src_mask)\n","\n","        encoded = src.contiguous().view(src.size(0), -1)\n","        # encoded: [batch_size, src_len * hidden_dim]\n","\n","        mean = self.relu(self.mean(encoded))\n","        log_var = self.relu(self.log_var(encoded))\n","        # mean, log_var: [batch_size, latent_dim]\n","\n","        return mean, log_var\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, hidden_dim, n_heads, pos_dim, dropout_ratio, device):\n","        super().__init__()\n","\n","        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n","        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pos_dim, dropout_ratio)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","        self.gsc = GatedSkipConnection(hidden_dim, hidden_dim)\n","\n","    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","\n","        # trg: [batch_size, trg_len, hidden_dim]\n","        # enc_src: [batch_size, src_len, hidden_dim]\n","        # trg_mask: [batch_size, 1, src_len-1, src_len-1]\n","        # src_mask: [batch_size, 1, 1, src_len]\n","\n","        # self attention\n","        # 자기 자신에 대하여 어텐션(attention)\n","        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n","\n","        # dropout, residual connection and layer norm\n","        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n","\n","        # trg: [batch_size, trg_len, hidden_dim]\n","\n","        # encoder attention\n","        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n","        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n","\n","        # dropout, residual connection and layer norm\n","        trg = self.enc_attn_layer_norm(self.gsc(trg, _trg))\n","        # trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n","        # trg: [batch_size, trg_len, hidden_dim]\n","\n","        # positionwise feedforward\n","        _trg = self.positionwise_feedforward(trg)\n","\n","        # dropout, residual and layer norm\n","        trg = self.ff_layer_norm(self.gsc(trg, _trg))\n","\n","        # trg = self.ff_layer_norm(trg + self.dropout(_trg))\n","        # trg: [batch_size, trg_len, hidden_dim]\n","        # attention: [batch_size, n_heads, trg_len, src_len]\n","\n","        return trg, attention\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, embed_dim, hidden_dim, latent_dim, n_layers, n_heads, pos_dim, dropout_ratio, max_len, device):\n","        super().__init__()\n","\n","        self.device = device\n","        self.hidden_dim = hidden_dim\n","        self.max_len = max_len\n","        self.latent_layer = nn.Linear(latent_dim, max_len*hidden_dim)\n","        self.relu = nn.ReLU()\n","\n","        self.tok_embedding = nn.Embedding(output_dim, embed_dim)\n","        self.pos_embedding = nn.Embedding(max_len, embed_dim)\n","        self.initial_linear = nn.Linear(embed_dim, hidden_dim)\n","        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pos_dim, dropout_ratio, device) for _ in range(n_layers)])\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n","\n","    def forward(self, trg, z, trg_mask, src_mask):\n","\n","        # z: [batch_size, latent_dim]\n","        # trg: [batch_size, src_len-1]\n","        # enc_src: [batch_size, src_len, hidden_dim]\n","        # trg_mask: [batch_size, src_len-1]\n","        # src_mask: [batch_size, src_len]\n","\n","        batch_size = trg.shape[0]\n","        trg_len = trg.shape[1]\n","\n","        z = self.relu(self.latent_layer(z))\n","        enc_src = z.view(batch_size, self.max_len, self.hidden_dim)\n","\n","        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        # pos: [batch_size, trg_len]\n","\n","        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n","        # trg: [batch_size, trg_len, embed_dim]\n","\n","        trg = self.initial_linear(trg)\n","\n","        for layer in self.layers:\n","            # 소스 마스크와 타겟 마스크 모두 사용\n","            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n","        # trg: [batch_size, trg_len, hidden_dim]\n","        # attention: [batch_size, n_heads, trg_len, src_len]\n","\n","        output = self.fc_out(trg)\n","        # output: [batch_size, trg_len, output_dim]\n","\n","        return output, attention\n","\n","class TransformerVAE(nn.Module):\n","    def __init__(self, args) :\n","        super().__init__()\n","\n","        self.encoder = Encoder(len(args['selfies_tokens']), args['embed_dim'], args['hidden_dim'], args['latent_dim'], args['enc_layers'], args['enc_heads'], args['enc_pos_dim'], args['enc_dropout'], args['selfies_max_len'], args['device'])\n","        self.decoder = Decoder(len(args['selfies_tokens']), args['embed_dim'], args['hidden_dim'], args['latent_dim'], args['dec_layers'], args['dec_heads'], args['dec_pos_dim'], args['dec_dropout'], args['selfies_max_len'], args['device'])\n","        self.pad_idx = args['pad_idx']\n","        self.device = device\n","        self.latent_dim = args['latent_dim']\n","        self.recon_criterion = nn.CrossEntropyLoss(ignore_index=args['pad_idx'])\n","\n","    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0(False)으로 설정\n","    def make_src_mask(self, src):\n","        # src: [batch_size, src_len]\n","        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n","        # src_mask: [batch_size, 1, 1, src_len]\n","        return src_mask\n","\n","    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n","    def make_trg_mask(self, trg):\n","        # trg: [batch_size, src_len-1]\n","\n","        trg_pad_mask = (trg != self.pad_idx).unsqueeze(1).unsqueeze(2)\n","        # trg_pad_mask: [batch_size, 1, 1, src_len-1]\n","\n","        trg_len = trg.shape[1]\n","        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n","        # trg_sub_mask: [src_len-1, src_len-1]\n","        trg_mask = trg_pad_mask & trg_sub_mask\n","        # trg_mask: [batch_size, 1, src_len-1, src_len-1]\n","        return trg_mask\n","\n","    def reparameterize(self, mean, log_var) :\n","        eps = torch.randn(mean.size(0), self.latent_dim).to(device)\n","        z = eps * torch.exp(log_var * .5) + mean\n","        return z\n","\n","    def vae_loss(self, x, mean, log_var, z, x_hat) :\n","        x_hat = x_hat.contiguous().view(-1, x_hat.shape[-1])\n","        x = x.contiguous().view(-1)\n","\n","        recon_loss = self.recon_criterion(x_hat, x)\n","        kl_loss = 0.5 * torch.sum(torch.square(mean) + torch.exp(log_var) - log_var -1)\n","\n","        return recon_loss + kl_loss\n","\n","    def forward(self, src):\n","        dec_src = src[:, 1:]\n","        trg = src[:, :-1]\n","        # src: [batch_size, len_src]\n","        # dec_src: [batch_size, len_src-1]\n","        # trg: [batch_size, len_src-1]\n","\n","        src_mask = self.make_src_mask(src)\n","        trg_mask = self.make_trg_mask(trg)\n","        # src_mask: [batch_size, 1, 1, len_src]\n","        # trg_mask: [batch_size, 1, len_src-1, len_src-1]\n","\n","        mean, log_var = self.encoder(src, src_mask)\n","        z = self.reparameterize(mean, log_var)\n","        # z: [batch_size, latent_dim]\n","        # enc_src: [batch_size, len_src, hidden_dim]\n","\n","        src_hat, attention = self.decoder(trg, z, trg_mask, src_mask)\n","        loss = self.vae_loss(dec_src, mean, log_var, z, src_hat)\n","        # output: [batch_size, len_src-1, output_dim]\n","        # attention: [batch_size, n_heads, len_src-1, len_src]\n","        return src_hat, attention, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izASaeuHeOEG"},"outputs":[],"source":["def run_train(model, train_iterator, val_iterator, optimizer, clip, device):\n","    epoch_train_loss = 0\n","    epoch_val_loss = 0\n","\n","    # train\n","    model.train()\n","\n","    for i, tokens in enumerate(train_iterator):\n","        tokens = tokens.to(device)\n","        optimizer.zero_grad()\n","        _, _, train_loss = model(tokens)\n","\n","        train_loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","\n","        epoch_train_loss += train_loss.item()\n","\n","    # validation\n","    model.eval()\n","\n","    with torch.no_grad() :\n","        for i, tokens in enumerate(val_iterator) :\n","            tokens = tokens.to(device)\n","\n","            _, _, val_loss = model(tokens)\n","            epoch_val_loss += val_loss.item()\n","\n","    epoch_train_loss /= len(train_iterator)\n","    epoch_val_loss /= len(val_iterator)\n","\n","    return epoch_train_loss, epoch_val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3phKm_Fl-snk"},"outputs":[],"source":["OPT_PARAMS = copy.copy(DEFAULT_PARAMS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1k9F6viDNhRl"},"outputs":[],"source":["# 하이퍼파라미터 최적화를 위해 wandb sweep을 설정 및 실행하는 클래스\n","class SweepSetting() :\n","    def __init__(self, sweep_setting, name) :\n","        wandb_api = wandb.Api()\n","        sweep_setting['name'] = name\n","\n","        self.device = DEFAULT_PARAMS['device']\n","        self.sweep_id = wandb.sweep(sweep=sweep_setting, project=SWEEP_PROJECT)\n","        self.count = sweep_setting['count']\n","        self.sweep_output = None\n","        self.best_run = None\n","\n","    def copy_params(self, run) :\n","        params = copy.copy(OPT_PARAMS)\n","        args = run.config\n","\n","        def load_config(elem) :\n","            if args.get(elem) :\n","                return args[elem]\n","            else :\n","                return params[elem]\n","\n","        return params\n","\n","    # hyperparameter를 sweep 설정에 따라 변경해가며 최적화된 hyperparameter value를 산출하는 메소드\n","    def sweep_callback(self) :\n","        with wandb.init() as run :\n","            params = self.copy_params(run)\n","            print(f'params : {params}')\n","\n","            train_dataloader = torch.utils.data.DataLoader(TRAIN_SET, batch_size=params['batch_size'], shuffle=False, drop_last = True)\n","            val_dataloader = torch.utils.data.DataLoader(VAL_SET, batch_size=params['batch_size'], shuffle=False, drop_last = True)\n","\n","            model = TransformerVAE(params).to(self.device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n","            epochs = params['epochs']\n","\n","            for epoch in tqdm(range(1, epochs + 1)) :\n","                epoch_train_loss, epoch_val_loss = run_train(model, train_dataloader, val_dataloader, optimizer, params['clip'], self.device)\n","                wandb.log({'epoch': epoch, 'epoch_train_loss': epoch_train_loss, 'epoch_val_loss': epoch_val_loss})\n","\n","        wandb.finish()\n","        print('='*150)\n","\n","    # 스윕 실행\n","    def start_agent(self) :\n","        wandb.agent(self.sweep_id, project=SWEEP_PROJECT, function=self.sweep_callback, count=self.count)\n","\n","    # 스윕 결과로부터 최적화된 hyperparameter 반환\n","    def get_best_params(self) :\n","        wandb_api = wandb.Api()\n","        self.sweep_output = wandb_api.sweep(f'{ENTITY}/{SWEEP_PROJECT}/{self.sweep_id}')\n","        self.best_run = sorted(self.sweep_output.runs, key=lambda r: r.summary.get('epoch_val_loss', float('inf')))[0]\n","\n","        temp = json.loads(self.best_run.json_config)\n","        best_params = copy.copy(OPT_PARAMS)\n","\n","        for key, value in temp.items() :\n","                best_params[key] = temp[key]['value']\n","\n","        return best_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYBWF7c3CiNs"},"outputs":[],"source":["# 모델의 학습, 테스트, 파라미터 계산 및 저장, wandb artifact로부터 모델 불러오기를 수행하는 클래스\n","class Trial() :\n","    def __init__(self, model, optimizer, params, use_wb, scheduler=None) :\n","        self.device = OPT_PARAMS['device']\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","        self.params = params\n","        self.use_wb = use_wb\n","        self.clip = OPT_PARAMS['clip']\n","        self.model_path = '/content/drive/MyDrive/Colab Notebooks/Python/Portfolio/model/'\n","        self.start_epoch = 1\n","        self.run = None\n","        self.report = None\n","\n","        self.model.apply(self.initialize_weights)\n","\n","    # Wandb 세션 초기화\n","    def wandb_init(self) :\n","        if self.use_wb :\n","            wandb.finish()\n","\n","            wandb_api = wandb.Api()\n","            api_runs = wandb_api.runs(f'{ENTITY}/{TRAIN_PROJECT}')\n","            run = wandb.init(project=TRAIN_PROJECT, name=f\"trial_{len(api_runs)+1}\")\n","            report = wandb_api.run(f'{ENTITY}/{TRAIN_PROJECT}/{run.id}')\n","\n","            self.run, self.report = run, report\n","\n","    def initialize_weights(self, m):\n","        if hasattr(m, 'weight') and m.weight is not None and m.weight.dim() > 1:\n","            nn.init.xavier_uniform_(m.weight.data)\n","\n","    # 입력한 run_id에 해당하는 실행 정보를 불러옴\n","    def wandb_load_run(self, run_id) :\n","        if self.use_wb :\n","            wandb_api = wandb.Api()\n","            run = wandb.init(project=TRAIN_PROJECT, id=run_id, resume=True)\n","            report = wandb_api.run(f'{ENTITY}/{TRAIN_PROJECT}/{run.id}')\n","\n","            self.run, self.report = run, report\n","\n","    # 모델의 학습, 최적화된 모델을 wandb 서버에 저장하는 메소드\n","    def train(self, train_dataloader, val_dataloader, start_epoch=1) :\n","        epochs = self.params['epochs']\n","        period = self.params['period']\n","        train_loss_list = []\n","        val_loss_list = []\n","\n","        today = datetime.now()\n","        date_str = today.strftime('%y%m%d')\n","        best_model_name = f'{TRAIN_PROJECT}_best_model_{date_str}.pth'\n","\n","        # 가장 낮은 validation loss값을 기준으로 모델의 파라미터 저장\n","        best_val_loss = float('inf')\n","\n","        for epoch in tqdm(range(start_epoch, epochs + 1)) :\n","            epoch_train_loss, epoch_val_loss = run_train(self.model, train_dataloader, val_dataloader, self.optimizer, self.clip, self.device )\n","\n","            train_loss_list.append(epoch_train_loss)\n","            val_loss_list.append(epoch_val_loss)\n","\n","            if self.params['use_scheduler'] and self.scheduler != None :\n","                self.scheduler.step(epoch_val_loss)\n","\n","            if self.use_wb :\n","                self.run.log({'epoch': epoch, 'epoch_train_loss': epoch_train_loss, 'epoch_val_loss': epoch_val_loss})\n","\n","                if epoch_val_loss < best_val_loss :\n","                    best_val_loss = epoch_val_loss\n","                    torch.save({\n","                    'epoch': epoch,\n","                    'model_state_dict': self.model.state_dict(),\n","                    'optimizer_state_dict': self.optimizer.state_dict(),\n","                    'epoch_val_loss': epoch_val_loss,\n","                    }, f'{self.model_path}{best_model_name}')\n","\n","            if epoch == 1 or epoch % period == 0 :\n","                print(f'{\"epoch\":>12} {epoch:<4} / {epochs:>4}  {\"[epoch_train_loss :\":>15} {epoch_train_loss:.5f}] {\"[epoch_val_loss :\":>12} {epoch_val_loss:.5f}] {\"[lr :\":>8} {self.optimizer.param_groups[0][\"lr\"]:.8f}]')\n","\n","        return train_loss_list, val_loss_list\n","\n","    # 학습된 모델을 테스트하는 메소드\n","    def test(self, test_dataloader) :\n","\n","        self.model.eval()\n","        with torch.no_grad() :\n","            tokens = next(iter(test_dataloader))\n","            tokens = tokens.to(self.device)\n","\n","            _, _, test_loss = self.model(tokens)\n","            test_loss = test_loss.detach().cpu().numpy()\n","\n","        if self.use_wb :\n","            wandb_api = wandb.Api()\n","            self.run.summary['test_loss'] = test_loss\n","            self.report = wandb_api.run(f'{ENTITY}/{TRAIN_PROJECT}/{self.run.id}')\n","\n","        return test_loss\n","\n","    def count_parameters(self) :\n","        table = PrettyTable(['Modules', 'Parameters'])\n","        total_params = 0\n","\n","        for name, parameter in self.model.named_parameters() :\n","            if not parameter.requires_grad :\n","                continue\n","\n","            param = parameter.numel()\n","            table.add_row([name, param])\n","            total_params += param\n","\n","        print(table)\n","        print(f'Total Trainable Params : {total_params}')\n","        return total_params\n","\n","    def upload(self, best_model_name) :\n","\n","        if self.use_wb :\n","            wandb_api = wandb.Api()\n","            self.report = wandb_api.run(f'{ENTITY}/{TRAIN_PROJECT}/{self.run.id}')\n","\n","            artifact = wandb.Artifact(best_model_name, type='model')\n","            artifact.add_file(f'{self.model_path}{best_model_name}')\n","\n","            self.run.log_artifact(artifact)\n","\n","    # wandb에 저장한 모델의 파라미터를 불러오는 메소드.\n","    def load_model(self, file_name, from_wandb=False) :\n","        if from_wandb :\n","            model_name = (file_name.split('/')[-1]).split(':')[0]\n","\n","            artifact = self.run.use_artifact(file_name, type='model')\n","            artifact_dir = artifact.download()\n","            artifact_state_dict = torch.load(os.path.join(artifact_dir, model_name))\n","\n","        else :\n","            artifact_state_dict = torch.load(f'{self.model_path}{file_name}')\n","\n","        self.model = TransformerVAE(self.params)\n","        self.model.load_state_dict(artifact_state_dict['model_state_dict'])\n","        self.model.to(self.device)\n","\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.params['learning_rate'])\n","        self.optimizer.load_state_dict(artifact_state_dict['optimizer_state_dict'])\n","\n","        self.start_epoch = artifact_state_dict['epoch']\n","\n","    def gen_mols(self, target_smiles, noise_size) :\n","        max_len = self.params['selfies_max_len']\n","        selfies_tokens = self.params['selfies_tokens']\n","        selfies_reverse_tokens = self.params['selfies_reverse_tokens']\n","        latent_dim = self.params['latent_dim']\n","\n","        gen_smiles = torch.zeros((1, max_len))\n","        gen_smiles[0][0] = selfies_tokens['<sos>']\n","\n","        for idx, tok in enumerate(selfies.split_selfies(selfies.encoder(target_smiles)), 1) :\n","            gen_smiles[0][idx] = selfies_tokens[tok]\n","        gen_smiles[0][idx+1] = selfies_tokens['<eos>']\n","\n","        gen_src = gen_smiles.type(torch.LongTensor)\n","\n","        def gen(noise) :\n","            src_mask = self.model.make_src_mask(gen_src).to(device)\n","            trg_index = [selfies_tokens['<sos>']]\n","\n","            for i in range(max_len) :\n","                trg_tensor = torch.LongTensor(trg_index).unsqueeze(0).to(device)\n","                trg_mask = self.model.make_trg_mask(trg_tensor).to(device)\n","                with torch.no_grad() :\n","                    output, attention = self.model.decoder(trg_tensor, noise, trg_mask, src_mask)\n","                pred_token = output.argmax(2)[:, -1].item()\n","                trg_index.append(pred_token)\n","\n","                if pred_token == selfies_tokens['<eos>'] :\n","                    break\n","\n","            result_smiles = ''.join([selfies_reverse_tokens[tok] for tok in trg_index][1:-1])\n","            return selfies.decoder(result_smiles)\n","\n","\n","        with torch.no_grad() :\n","            noise = torch.randn(noise_size, latent_dim).to(device)\n","\n","        gen_smiles = set()\n","\n","        for n in range(noise_size) :\n","            result_smiles = gen(noise[n])\n","\n","            gen_mol = Chem.MolFromSmiles(result_smiles)\n","            if gen_mol != None :\n","                gen_smiles.add(result_smiles)\n","\n","        return list(gen_smiles)"]},{"cell_type":"markdown","metadata":{"id":"I6rZ9Jvc-v2d"},"source":["# Sweep"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11606,"status":"ok","timestamp":1692595037085,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"F_lxtG4gPFZF","outputId":"424c4d3d-cb9f-4dd8-e86d-f6337019f5ef"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["dir_path = '/content/drive/MyDrive/Colab Notebooks/jsons/'\n","login_file_name = 'wandb.json'\n","login_file_path = os.path.join(dir_path, login_file_name)\n","\n","with open(login_file_path, 'r') as f :\n","    json_wandb = json.load(f)\n","\n","wandb.login(key=json_wandb['key'])\n","time.sleep(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1692508958189,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"77rISXTuPI6O","outputId":"9de19e12-f1f7-4eb9-9007-affab3fa111c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['1_learning_rate.yaml']\n"]}],"source":["yaml_files = sorted(os.listdir(os.path.join(dir_path, 'TRANS_VAE_SELFIES')))\n","list_sweep = []\n","print(yaml_files)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e03a21816d7b46e4a175e542b0bbd45a","01dabf1d33dd43ff9d822a9882445e8e","bb1a2624dcb2492d84d6dd0006c8fe31","144c71ea2af6406a87553d0b554e4716","d6120e24392f42e8bcba38183f3c043d","368ab894d8c0492cab9b313d2b2e1b28","188e06db684942cf9ae1262857127558","17105902b69e4c73b9f8307858d605f2","87bae3b336914322b71ce2413cc8f45b","b1b2e58161554544bdee4d5c86284e69","08be7ac36f804c65bbc4aea49b24cd41","d4a66074d4484c449b6844115cbf3ea6","d3164a68fc3d4658ae998778bf961e27","cd3b5ad46dbf4e5d86c9bd7b1a9707f0","452bba36c50a4aa7b1fbba879203a070","a3c3e96249bb47c786cea89ffe7eb2c3"]},"executionInfo":{"elapsed":7241846,"status":"ok","timestamp":1692516200006,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"KSthEBCxQHtI","outputId":"3bab9191-abec-43ed-eafd-f8e96c0edd29"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","====================================================================== Condition 1 ======================================================================\n","\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('count' was unexpected)\n"]},{"name":"stdout","output_type":"stream","text":["Create sweep with ID: oqn7k096\n","Sweep URL: https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4f47uz4g with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrossi22\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_052242-4f47uz4g</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/4f47uz4g' target=\"_blank\">light-sweep-1</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/4f47uz4g' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/4f47uz4g</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [16:53<00:00, 50.66s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.37593</td></tr><tr><td>epoch_val_loss</td><td>1.29773</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">light-sweep-1</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/4f47uz4g' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/4f47uz4g</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_052242-4f47uz4g/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fxe8a6r9 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_053955-fxe8a6r9</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/fxe8a6r9' target=\"_blank\">laced-sweep-2</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/fxe8a6r9' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/fxe8a6r9</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [16:51<00:00, 50.57s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.3714</td></tr><tr><td>epoch_val_loss</td><td>1.29793</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">laced-sweep-2</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/fxe8a6r9' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/fxe8a6r9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_053955-fxe8a6r9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmijgnx8 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_055704-lmijgnx8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/lmijgnx8' target=\"_blank\">vague-sweep-3</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/lmijgnx8' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/lmijgnx8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [16:49<00:00, 50.47s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e03a21816d7b46e4a175e542b0bbd45a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▇▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.38946</td></tr><tr><td>epoch_val_loss</td><td>1.31963</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">vague-sweep-3</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/lmijgnx8' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/lmijgnx8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_055704-lmijgnx8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8cagysgo with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_061413-8cagysgo</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/8cagysgo' target=\"_blank\">stellar-sweep-4</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/8cagysgo' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/8cagysgo</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [16:53<00:00, 50.68s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87bae3b336914322b71ce2413cc8f45b","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▆▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.38368</td></tr><tr><td>epoch_val_loss</td><td>1.31123</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">stellar-sweep-4</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/8cagysgo' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/8cagysgo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_061413-8cagysgo/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3bni8doe with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_063126-3bni8doe</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/3bni8doe' target=\"_blank\">swept-sweep-5</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/3bni8doe' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/3bni8doe</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [17:01<00:00, 51.09s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.38107</td></tr><tr><td>epoch_val_loss</td><td>1.30236</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">swept-sweep-5</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/3bni8doe' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/3bni8doe</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_063126-3bni8doe/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7rf77sg5 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_064851-7rf77sg5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/7rf77sg5' target=\"_blank\">upbeat-sweep-6</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/7rf77sg5' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/7rf77sg5</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [16:55<00:00, 50.77s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.39312</td></tr><tr><td>epoch_val_loss</td><td>1.31683</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">upbeat-sweep-6</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/7rf77sg5' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/7rf77sg5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_064851-7rf77sg5/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kup5jsbt with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n"]},{"data":{"text/html":["Tracking run with wandb version 0.15.8"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20230820_070604-kup5jsbt</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/kup5jsbt' target=\"_blank\">crisp-sweep-7</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View sweep at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/sweeps/oqn7k096</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/kup5jsbt' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/kup5jsbt</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["params : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [17:02<00:00, 51.10s/it]\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_val_loss</td><td>█▇▅▅▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>epoch_train_loss</td><td>1.38092</td></tr><tr><td>epoch_val_loss</td><td>1.30576</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">crisp-sweep-7</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/kup5jsbt' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_SWEEP/runs/kup5jsbt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20230820_070604-kup5jsbt/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["======================================================================================================================================================\n","\n","best hyperparameters : {'device': device(type='cpu'), 'batch_size': 128, 'learning_rate': 0.0001, 'epochs': 20, 'embed_dim': 32, 'latent_dim': 64, 'hidden_dim': 32, 'enc_layers': 4, 'dec_layers': 4, 'enc_heads': 8, 'dec_heads': 8, 'enc_pos_dim': 256, 'dec_pos_dim': 256, 'enc_dropout': 0.1, 'dec_dropout': 0.1, 'pad_idx': 0, 'clip': 0.01, 'use_scheduler': False, 'selfies_max_len': 34, 'selfies_tokens': {'<pad>': 0, '<sos>': 1, '<eos>': 2, '[Cl]': 3, '[NH1]': 4, '[#C]': 5, '[O]': 6, '[=O]': 7, '[Br]': 8, '[#Branch2]': 9, '[=Ring1]': 10, '[Ring1]': 11, '[S]': 12, '[=Branch2]': 13, '[=Branch1]': 14, '[Ring2]': 15, '[Branch1]': 16, '[C]': 17, '[Branch2]': 18, '[N]': 19, '[=Ring2]': 20, '[P]': 21, '[#Branch1]': 22, '[=S]': 23, '[=C]': 24, '[=N]': 25, '[#N]': 26, '[F]': 27}, 'selfies_reverse_tokens': {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '[Cl]', 4: '[NH1]', 5: '[#C]', 6: '[O]', 7: '[=O]', 8: '[Br]', 9: '[#Branch2]', 10: '[=Ring1]', 11: '[Ring1]', 12: '[S]', 13: '[=Branch2]', 14: '[=Branch1]', 15: '[Ring2]', 16: '[Branch1]', 17: '[C]', 18: '[Branch2]', 19: '[N]', 20: '[=Ring2]', 21: '[P]', 22: '[#Branch1]', 23: '[=S]', 24: '[=C]', 25: '[=N]', 26: '[#N]', 27: '[F]'}}\n","\n","------------------------------------------------------------------------------------------------------------------------------------------------------\n"]}],"source":["for idx, yf in enumerate(yaml_files, 1) :\n","    print(f'\\n{\"=\"*70} Condition {idx} {\"=\"*70}\\n')\n","    print('-'*150)\n","    sweep_setting_name = yf\n","    sweep_setting_path = os.path.join(dir_path, 'TRANS_VAE_SELFIES', sweep_setting_name)\n","\n","    with open(sweep_setting_path, 'r') as f :\n","        sweep_setting = yaml.load(f, Loader=yaml.FullLoader)\n","        current_sweep = SweepSetting(sweep_setting, sweep_setting_name.split('.')[0])\n","        current_sweep.start_agent()\n","\n","        OPT_PARAMS = current_sweep.get_best_params()\n","        print(f'\\nbest hyperparameters : {OPT_PARAMS}\\n')\n","        print('-'*150)\n","\n","        list_sweep.append(current_sweep)"]},{"cell_type":"markdown","metadata":{"id":"26wJbCn9Fooz"},"source":["#Train&Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10021,"status":"ok","timestamp":1692679165620,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"69tFrC88GLWO","outputId":"67bead06-0903-4cfc-9783-6b437047ef18"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["dir_path = '/content/drive/MyDrive/Colab Notebooks/jsons/'\n","login_file_name = 'wandb.json'\n","login_file_path = os.path.join(dir_path, login_file_name)\n","\n","with open(login_file_path, 'r') as f :\n","    json_wandb = json.load(f)\n","\n","wandb.login(key=json_wandb['key'])\n","time.sleep(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZo1ep9AFrPz"},"outputs":[],"source":["params = copy.copy(OPT_PARAMS)\n","params['epochs'] = 100\n","params['period'] = 5\n","params['schd_patience'] = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1692679165621,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"tuEN3rIwe0kA","outputId":"31d9f74d-b51e-44ea-e6f6-62e2880d32e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["2604\n"]}],"source":["train_loader = torch.utils.data.DataLoader(TRAIN_SET, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n","val_loader = torch.utils.data.DataLoader(VAL_SET, batch_size=params['batch_size'], shuffle=False, drop_last=True)\n","test_loader = torch.utils.data.DataLoader(TEST_SET, batch_size=len(TEST_SET), shuffle=False, drop_last=False)\n","print(len(train_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQAGKVdVh9CP"},"outputs":[],"source":["model = TransformerVAE(params).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n","scheduler = ReduceLROnPlateau(optimizer, factor=params['schd_factor'], patience=params['schd_patience'], min_lr=params['schd_min_lr'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1692679171207,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"EBTz4AhDiQkU","outputId":"0d87ae67-cda7-47a5-ced0-d69ef58146d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------+------------+\n","|                         Modules                          | Parameters |\n","+----------------------------------------------------------+------------+\n","|               encoder.tok_embedding.weight               |    1344    |\n","|               encoder.pos_embedding.weight               |    2336    |\n","|              encoder.initial_linear.weight               |    2048    |\n","|               encoder.initial_linear.bias                |     64     |\n","|     encoder.en_layers.0.self_attn_layer_norm.weight      |     64     |\n","|      encoder.en_layers.0.self_attn_layer_norm.bias       |     64     |\n","|      encoder.en_layers.0.self_attention.fc_q.weight      |    4096    |\n","|       encoder.en_layers.0.self_attention.fc_q.bias       |     64     |\n","|      encoder.en_layers.0.self_attention.fc_k.weight      |    4096    |\n","|       encoder.en_layers.0.self_attention.fc_k.bias       |     64     |\n","|      encoder.en_layers.0.self_attention.fc_v.weight      |    4096    |\n","|       encoder.en_layers.0.self_attention.fc_v.bias       |     64     |\n","|      encoder.en_layers.0.self_attention.fc_o.weight      |    4096    |\n","|       encoder.en_layers.0.self_attention.fc_o.bias       |     64     |\n","| encoder.en_layers.0.positionwise_feedforward.fc_1.weight |   16384    |\n","|  encoder.en_layers.0.positionwise_feedforward.fc_1.bias  |    256     |\n","| encoder.en_layers.0.positionwise_feedforward.fc_2.weight |   16384    |\n","|  encoder.en_layers.0.positionwise_feedforward.fc_2.bias  |     64     |\n","|         encoder.en_layers.0.ff_layer_norm.weight         |     64     |\n","|          encoder.en_layers.0.ff_layer_norm.bias          |     64     |\n","|          encoder.en_layers.0.gsc.linear.weight           |    4096    |\n","|      encoder.en_layers.0.gsc.linear_coef_in.weight       |    4096    |\n","|       encoder.en_layers.0.gsc.linear_coef_in.bias        |     64     |\n","|      encoder.en_layers.0.gsc.linear_coef_out.weight      |    4096    |\n","|       encoder.en_layers.0.gsc.linear_coef_out.bias       |     64     |\n","|     encoder.en_layers.1.self_attn_layer_norm.weight      |     64     |\n","|      encoder.en_layers.1.self_attn_layer_norm.bias       |     64     |\n","|      encoder.en_layers.1.self_attention.fc_q.weight      |    4096    |\n","|       encoder.en_layers.1.self_attention.fc_q.bias       |     64     |\n","|      encoder.en_layers.1.self_attention.fc_k.weight      |    4096    |\n","|       encoder.en_layers.1.self_attention.fc_k.bias       |     64     |\n","|      encoder.en_layers.1.self_attention.fc_v.weight      |    4096    |\n","|       encoder.en_layers.1.self_attention.fc_v.bias       |     64     |\n","|      encoder.en_layers.1.self_attention.fc_o.weight      |    4096    |\n","|       encoder.en_layers.1.self_attention.fc_o.bias       |     64     |\n","| encoder.en_layers.1.positionwise_feedforward.fc_1.weight |   16384    |\n","|  encoder.en_layers.1.positionwise_feedforward.fc_1.bias  |    256     |\n","| encoder.en_layers.1.positionwise_feedforward.fc_2.weight |   16384    |\n","|  encoder.en_layers.1.positionwise_feedforward.fc_2.bias  |     64     |\n","|         encoder.en_layers.1.ff_layer_norm.weight         |     64     |\n","|          encoder.en_layers.1.ff_layer_norm.bias          |     64     |\n","|          encoder.en_layers.1.gsc.linear.weight           |    4096    |\n","|      encoder.en_layers.1.gsc.linear_coef_in.weight       |    4096    |\n","|       encoder.en_layers.1.gsc.linear_coef_in.bias        |     64     |\n","|      encoder.en_layers.1.gsc.linear_coef_out.weight      |    4096    |\n","|       encoder.en_layers.1.gsc.linear_coef_out.bias       |     64     |\n","|     encoder.en_layers.2.self_attn_layer_norm.weight      |     64     |\n","|      encoder.en_layers.2.self_attn_layer_norm.bias       |     64     |\n","|      encoder.en_layers.2.self_attention.fc_q.weight      |    4096    |\n","|       encoder.en_layers.2.self_attention.fc_q.bias       |     64     |\n","|      encoder.en_layers.2.self_attention.fc_k.weight      |    4096    |\n","|       encoder.en_layers.2.self_attention.fc_k.bias       |     64     |\n","|      encoder.en_layers.2.self_attention.fc_v.weight      |    4096    |\n","|       encoder.en_layers.2.self_attention.fc_v.bias       |     64     |\n","|      encoder.en_layers.2.self_attention.fc_o.weight      |    4096    |\n","|       encoder.en_layers.2.self_attention.fc_o.bias       |     64     |\n","| encoder.en_layers.2.positionwise_feedforward.fc_1.weight |   16384    |\n","|  encoder.en_layers.2.positionwise_feedforward.fc_1.bias  |    256     |\n","| encoder.en_layers.2.positionwise_feedforward.fc_2.weight |   16384    |\n","|  encoder.en_layers.2.positionwise_feedforward.fc_2.bias  |     64     |\n","|         encoder.en_layers.2.ff_layer_norm.weight         |     64     |\n","|          encoder.en_layers.2.ff_layer_norm.bias          |     64     |\n","|          encoder.en_layers.2.gsc.linear.weight           |    4096    |\n","|      encoder.en_layers.2.gsc.linear_coef_in.weight       |    4096    |\n","|       encoder.en_layers.2.gsc.linear_coef_in.bias        |     64     |\n","|      encoder.en_layers.2.gsc.linear_coef_out.weight      |    4096    |\n","|       encoder.en_layers.2.gsc.linear_coef_out.bias       |     64     |\n","|     encoder.en_layers.3.self_attn_layer_norm.weight      |     64     |\n","|      encoder.en_layers.3.self_attn_layer_norm.bias       |     64     |\n","|      encoder.en_layers.3.self_attention.fc_q.weight      |    4096    |\n","|       encoder.en_layers.3.self_attention.fc_q.bias       |     64     |\n","|      encoder.en_layers.3.self_attention.fc_k.weight      |    4096    |\n","|       encoder.en_layers.3.self_attention.fc_k.bias       |     64     |\n","|      encoder.en_layers.3.self_attention.fc_v.weight      |    4096    |\n","|       encoder.en_layers.3.self_attention.fc_v.bias       |     64     |\n","|      encoder.en_layers.3.self_attention.fc_o.weight      |    4096    |\n","|       encoder.en_layers.3.self_attention.fc_o.bias       |     64     |\n","| encoder.en_layers.3.positionwise_feedforward.fc_1.weight |   16384    |\n","|  encoder.en_layers.3.positionwise_feedforward.fc_1.bias  |    256     |\n","| encoder.en_layers.3.positionwise_feedforward.fc_2.weight |   16384    |\n","|  encoder.en_layers.3.positionwise_feedforward.fc_2.bias  |     64     |\n","|         encoder.en_layers.3.ff_layer_norm.weight         |     64     |\n","|          encoder.en_layers.3.ff_layer_norm.bias          |     64     |\n","|          encoder.en_layers.3.gsc.linear.weight           |    4096    |\n","|      encoder.en_layers.3.gsc.linear_coef_in.weight       |    4096    |\n","|       encoder.en_layers.3.gsc.linear_coef_in.bias        |     64     |\n","|      encoder.en_layers.3.gsc.linear_coef_out.weight      |    4096    |\n","|       encoder.en_layers.3.gsc.linear_coef_out.bias       |     64     |\n","|                   encoder.mean.weight                    |   598016   |\n","|                    encoder.mean.bias                     |    128     |\n","|                  encoder.log_var.weight                  |   598016   |\n","|                   encoder.log_var.bias                   |    128     |\n","|               decoder.latent_layer.weight                |   598016   |\n","|                decoder.latent_layer.bias                 |    4672    |\n","|               decoder.tok_embedding.weight               |    1344    |\n","|               decoder.pos_embedding.weight               |    2336    |\n","|              decoder.initial_linear.weight               |    2048    |\n","|               decoder.initial_linear.bias                |     64     |\n","|       decoder.layers.0.self_attn_layer_norm.weight       |     64     |\n","|        decoder.layers.0.self_attn_layer_norm.bias        |     64     |\n","|       decoder.layers.0.enc_attn_layer_norm.weight        |     64     |\n","|        decoder.layers.0.enc_attn_layer_norm.bias         |     64     |\n","|          decoder.layers.0.ff_layer_norm.weight           |     64     |\n","|           decoder.layers.0.ff_layer_norm.bias            |     64     |\n","|       decoder.layers.0.self_attention.fc_q.weight        |    4096    |\n","|        decoder.layers.0.self_attention.fc_q.bias         |     64     |\n","|       decoder.layers.0.self_attention.fc_k.weight        |    4096    |\n","|        decoder.layers.0.self_attention.fc_k.bias         |     64     |\n","|       decoder.layers.0.self_attention.fc_v.weight        |    4096    |\n","|        decoder.layers.0.self_attention.fc_v.bias         |     64     |\n","|       decoder.layers.0.self_attention.fc_o.weight        |    4096    |\n","|        decoder.layers.0.self_attention.fc_o.bias         |     64     |\n","|      decoder.layers.0.encoder_attention.fc_q.weight      |    4096    |\n","|       decoder.layers.0.encoder_attention.fc_q.bias       |     64     |\n","|      decoder.layers.0.encoder_attention.fc_k.weight      |    4096    |\n","|       decoder.layers.0.encoder_attention.fc_k.bias       |     64     |\n","|      decoder.layers.0.encoder_attention.fc_v.weight      |    4096    |\n","|       decoder.layers.0.encoder_attention.fc_v.bias       |     64     |\n","|      decoder.layers.0.encoder_attention.fc_o.weight      |    4096    |\n","|       decoder.layers.0.encoder_attention.fc_o.bias       |     64     |\n","|  decoder.layers.0.positionwise_feedforward.fc_1.weight   |   16384    |\n","|   decoder.layers.0.positionwise_feedforward.fc_1.bias    |    256     |\n","|  decoder.layers.0.positionwise_feedforward.fc_2.weight   |   16384    |\n","|   decoder.layers.0.positionwise_feedforward.fc_2.bias    |     64     |\n","|            decoder.layers.0.gsc.linear.weight            |    4096    |\n","|        decoder.layers.0.gsc.linear_coef_in.weight        |    4096    |\n","|         decoder.layers.0.gsc.linear_coef_in.bias         |     64     |\n","|       decoder.layers.0.gsc.linear_coef_out.weight        |    4096    |\n","|        decoder.layers.0.gsc.linear_coef_out.bias         |     64     |\n","|       decoder.layers.1.self_attn_layer_norm.weight       |     64     |\n","|        decoder.layers.1.self_attn_layer_norm.bias        |     64     |\n","|       decoder.layers.1.enc_attn_layer_norm.weight        |     64     |\n","|        decoder.layers.1.enc_attn_layer_norm.bias         |     64     |\n","|          decoder.layers.1.ff_layer_norm.weight           |     64     |\n","|           decoder.layers.1.ff_layer_norm.bias            |     64     |\n","|       decoder.layers.1.self_attention.fc_q.weight        |    4096    |\n","|        decoder.layers.1.self_attention.fc_q.bias         |     64     |\n","|       decoder.layers.1.self_attention.fc_k.weight        |    4096    |\n","|        decoder.layers.1.self_attention.fc_k.bias         |     64     |\n","|       decoder.layers.1.self_attention.fc_v.weight        |    4096    |\n","|        decoder.layers.1.self_attention.fc_v.bias         |     64     |\n","|       decoder.layers.1.self_attention.fc_o.weight        |    4096    |\n","|        decoder.layers.1.self_attention.fc_o.bias         |     64     |\n","|      decoder.layers.1.encoder_attention.fc_q.weight      |    4096    |\n","|       decoder.layers.1.encoder_attention.fc_q.bias       |     64     |\n","|      decoder.layers.1.encoder_attention.fc_k.weight      |    4096    |\n","|       decoder.layers.1.encoder_attention.fc_k.bias       |     64     |\n","|      decoder.layers.1.encoder_attention.fc_v.weight      |    4096    |\n","|       decoder.layers.1.encoder_attention.fc_v.bias       |     64     |\n","|      decoder.layers.1.encoder_attention.fc_o.weight      |    4096    |\n","|       decoder.layers.1.encoder_attention.fc_o.bias       |     64     |\n","|  decoder.layers.1.positionwise_feedforward.fc_1.weight   |   16384    |\n","|   decoder.layers.1.positionwise_feedforward.fc_1.bias    |    256     |\n","|  decoder.layers.1.positionwise_feedforward.fc_2.weight   |   16384    |\n","|   decoder.layers.1.positionwise_feedforward.fc_2.bias    |     64     |\n","|            decoder.layers.1.gsc.linear.weight            |    4096    |\n","|        decoder.layers.1.gsc.linear_coef_in.weight        |    4096    |\n","|         decoder.layers.1.gsc.linear_coef_in.bias         |     64     |\n","|       decoder.layers.1.gsc.linear_coef_out.weight        |    4096    |\n","|        decoder.layers.1.gsc.linear_coef_out.bias         |     64     |\n","|       decoder.layers.2.self_attn_layer_norm.weight       |     64     |\n","|        decoder.layers.2.self_attn_layer_norm.bias        |     64     |\n","|       decoder.layers.2.enc_attn_layer_norm.weight        |     64     |\n","|        decoder.layers.2.enc_attn_layer_norm.bias         |     64     |\n","|          decoder.layers.2.ff_layer_norm.weight           |     64     |\n","|           decoder.layers.2.ff_layer_norm.bias            |     64     |\n","|       decoder.layers.2.self_attention.fc_q.weight        |    4096    |\n","|        decoder.layers.2.self_attention.fc_q.bias         |     64     |\n","|       decoder.layers.2.self_attention.fc_k.weight        |    4096    |\n","|        decoder.layers.2.self_attention.fc_k.bias         |     64     |\n","|       decoder.layers.2.self_attention.fc_v.weight        |    4096    |\n","|        decoder.layers.2.self_attention.fc_v.bias         |     64     |\n","|       decoder.layers.2.self_attention.fc_o.weight        |    4096    |\n","|        decoder.layers.2.self_attention.fc_o.bias         |     64     |\n","|      decoder.layers.2.encoder_attention.fc_q.weight      |    4096    |\n","|       decoder.layers.2.encoder_attention.fc_q.bias       |     64     |\n","|      decoder.layers.2.encoder_attention.fc_k.weight      |    4096    |\n","|       decoder.layers.2.encoder_attention.fc_k.bias       |     64     |\n","|      decoder.layers.2.encoder_attention.fc_v.weight      |    4096    |\n","|       decoder.layers.2.encoder_attention.fc_v.bias       |     64     |\n","|      decoder.layers.2.encoder_attention.fc_o.weight      |    4096    |\n","|       decoder.layers.2.encoder_attention.fc_o.bias       |     64     |\n","|  decoder.layers.2.positionwise_feedforward.fc_1.weight   |   16384    |\n","|   decoder.layers.2.positionwise_feedforward.fc_1.bias    |    256     |\n","|  decoder.layers.2.positionwise_feedforward.fc_2.weight   |   16384    |\n","|   decoder.layers.2.positionwise_feedforward.fc_2.bias    |     64     |\n","|            decoder.layers.2.gsc.linear.weight            |    4096    |\n","|        decoder.layers.2.gsc.linear_coef_in.weight        |    4096    |\n","|         decoder.layers.2.gsc.linear_coef_in.bias         |     64     |\n","|       decoder.layers.2.gsc.linear_coef_out.weight        |    4096    |\n","|        decoder.layers.2.gsc.linear_coef_out.bias         |     64     |\n","|       decoder.layers.3.self_attn_layer_norm.weight       |     64     |\n","|        decoder.layers.3.self_attn_layer_norm.bias        |     64     |\n","|       decoder.layers.3.enc_attn_layer_norm.weight        |     64     |\n","|        decoder.layers.3.enc_attn_layer_norm.bias         |     64     |\n","|          decoder.layers.3.ff_layer_norm.weight           |     64     |\n","|           decoder.layers.3.ff_layer_norm.bias            |     64     |\n","|       decoder.layers.3.self_attention.fc_q.weight        |    4096    |\n","|        decoder.layers.3.self_attention.fc_q.bias         |     64     |\n","|       decoder.layers.3.self_attention.fc_k.weight        |    4096    |\n","|        decoder.layers.3.self_attention.fc_k.bias         |     64     |\n","|       decoder.layers.3.self_attention.fc_v.weight        |    4096    |\n","|        decoder.layers.3.self_attention.fc_v.bias         |     64     |\n","|       decoder.layers.3.self_attention.fc_o.weight        |    4096    |\n","|        decoder.layers.3.self_attention.fc_o.bias         |     64     |\n","|      decoder.layers.3.encoder_attention.fc_q.weight      |    4096    |\n","|       decoder.layers.3.encoder_attention.fc_q.bias       |     64     |\n","|      decoder.layers.3.encoder_attention.fc_k.weight      |    4096    |\n","|       decoder.layers.3.encoder_attention.fc_k.bias       |     64     |\n","|      decoder.layers.3.encoder_attention.fc_v.weight      |    4096    |\n","|       decoder.layers.3.encoder_attention.fc_v.bias       |     64     |\n","|      decoder.layers.3.encoder_attention.fc_o.weight      |    4096    |\n","|       decoder.layers.3.encoder_attention.fc_o.bias       |     64     |\n","|  decoder.layers.3.positionwise_feedforward.fc_1.weight   |   16384    |\n","|   decoder.layers.3.positionwise_feedforward.fc_1.bias    |    256     |\n","|  decoder.layers.3.positionwise_feedforward.fc_2.weight   |   16384    |\n","|   decoder.layers.3.positionwise_feedforward.fc_2.bias    |     64     |\n","|            decoder.layers.3.gsc.linear.weight            |    4096    |\n","|        decoder.layers.3.gsc.linear_coef_in.weight        |    4096    |\n","|         decoder.layers.3.gsc.linear_coef_in.bias         |     64     |\n","|       decoder.layers.3.gsc.linear_coef_out.weight        |    4096    |\n","|        decoder.layers.3.gsc.linear_coef_out.bias         |     64     |\n","|                  decoder.fc_out.weight                   |    2688    |\n","|                   decoder.fc_out.bias                    |     42     |\n","+----------------------------------------------------------+------------+\n","Total Trainable Params : 2379562\n"]},{"output_type":"execute_result","data":{"text/plain":["2379562"]},"metadata":{},"execution_count":20}],"source":["trial = Trial(model=model, optimizer=optimizer, params=params, use_wb=True, scheduler=scheduler)\n","trial.count_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"id":"1Wz9-zHQHVKd","executionInfo":{"status":"ok","timestamp":1692702614429,"user_tz":-540,"elapsed":23437548,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"}},"outputId":"5036e964-40a8-416d-9cd3-e17c8cb4756c"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrossi22\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.8"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230822_043936-t9z44fwe</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/100 [03:56<6:29:39, 236.16s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 1    /  100  [epoch_train_loss : 15.71173] [epoch_val_loss : 1.07550]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 5/100 [19:37<6:12:49, 235.47s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 5    /  100  [epoch_train_loss : 0.93426] [epoch_val_loss : 0.85625]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 10/100 [39:23<5:55:39, 237.11s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 10   /  100  [epoch_train_loss : 0.84485] [epoch_val_loss : 0.78088]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 15/100 [59:14<5:37:02, 237.91s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 15   /  100  [epoch_train_loss : 0.80285] [epoch_val_loss : 0.74377]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 20/100 [1:18:59<5:16:02, 237.04s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 20   /  100  [epoch_train_loss : 0.77676] [epoch_val_loss : 0.71605]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 25/100 [1:38:44<4:56:32, 237.23s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 25   /  100  [epoch_train_loss : 0.75837] [epoch_val_loss : 0.69848]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 30/100 [1:58:24<4:34:47, 235.53s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 30   /  100  [epoch_train_loss : 0.74389] [epoch_val_loss : 0.68502]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 35/100 [2:17:57<4:13:51, 234.33s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 35   /  100  [epoch_train_loss : 0.73258] [epoch_val_loss : 0.67710]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 40/100 [2:37:25<3:53:51, 233.85s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 40   /  100  [epoch_train_loss : 0.72280] [epoch_val_loss : 0.66765]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 45/100 [2:56:54<3:34:23, 233.88s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 45   /  100  [epoch_train_loss : 0.71460] [epoch_val_loss : 0.66015]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 50/100 [3:16:25<3:14:59, 234.00s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 50   /  100  [epoch_train_loss : 0.70740] [epoch_val_loss : 0.65407]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 55/100 [3:35:53<2:55:16, 233.71s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 55   /  100  [epoch_train_loss : 0.70096] [epoch_val_loss : 0.65115]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 60/100 [3:55:19<2:35:25, 233.13s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 60   /  100  [epoch_train_loss : 0.69554] [epoch_val_loss : 0.64911]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 65/100 [4:14:42<2:15:44, 232.70s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 65   /  100  [epoch_train_loss : 0.69097] [epoch_val_loss : 0.64343]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 70/100 [4:34:10<1:56:48, 233.63s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 70   /  100  [epoch_train_loss : 0.68670] [epoch_val_loss : 0.64369]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 75/100 [4:53:37<1:37:14, 233.36s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 75   /  100  [epoch_train_loss : 0.68297] [epoch_val_loss : 0.63711]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 80/100 [5:13:00<1:17:38, 232.90s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 80   /  100  [epoch_train_loss : 0.67942] [epoch_val_loss : 0.63035]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 85/100 [5:32:26<58:16, 233.10s/it]  "]},{"output_type":"stream","name":"stdout","text":["       epoch 85   /  100  [epoch_train_loss : 0.67595] [epoch_val_loss : 0.63413]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 90/100 [5:51:49<38:45, 232.59s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 90   /  100  [epoch_train_loss : 0.67315] [epoch_val_loss : 0.62936]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 95/100 [6:11:10<19:21, 232.36s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 95   /  100  [epoch_train_loss : 0.67081] [epoch_val_loss : 0.62941]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [6:30:33<00:00, 234.33s/it]"]},{"output_type":"stream","name":"stdout","text":["       epoch 100  /  100  [epoch_train_loss : 0.66823] [epoch_val_loss : 0.62201]    [lr : 0.00020000]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["trial.wandb_init()\n","train_loss_list, val_loss_list = trial.train(train_loader, val_loader)"]},{"cell_type":"code","source":["trial.upload('TRANS_VAE_SELFIES_TRAIN_best_model_230822.pth')"],"metadata":{"id":"5c0uH9LfaZ9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZYgY4pceGMV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692702715083,"user_tz":-540,"elapsed":2602,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"}},"outputId":"fee06a83-0650-482f-9937-09258aa77180"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(0.6237212, dtype=float32)"]},"metadata":{},"execution_count":23}],"source":["test_loss = trial.test(test_loader)\n","test_loss"]},{"cell_type":"code","source":["dutasteride = 'CC12CCC3C(C1CCC2C(=O)NC4=C(C=CC(=C4)C(F)(F)F)C(F)(F)F)CCC5C3(C=CC(=O)N5)C'\n","duta_selfies = selfies.encoder(dutasteride)\n","generating_size = 1000\n","\n","print(f'dutasteride : {dutasteride}')\n","print(f'dutasteride in dataset? : {duta_selfies in selfies_list}')\n","\n","gen_mols = trial.gen_mols(dutasteride, generating_size)\n","print(f'generated mols : {len(gen_mols)}/{generating_size}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMZNSAff86Bj","executionInfo":{"status":"ok","timestamp":1692707269859,"user_tz":-540,"elapsed":403379,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"}},"outputId":"b6c6f578-82e4-45e2-a0a4-92ec94feecf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dutasteride : CC12CCC3C(C1CCC2C(=O)NC4=C(C=CC(=C4)C(F)(F)F)C(F)(F)F)CCC5C3(C=CC(=O)N5)C\n","dutasteride in dataset? : False\n","generated mols : 265/1000\n"]}]},{"cell_type":"code","source":["print(f'dutasteride : {dutasteride}')\n","display(Chem.MolFromSmiles(dutasteride))\n","\n","for i, smiles in enumerate(gen_mols) :\n","    print(f'\\n{i} : {smiles}')\n","    img = Draw.MolToImage(Chem.MolFromSmiles(smiles))\n","    display(img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1E4QdqgSFmXBIAUp41MPZuzg4HyC6Aw9x"},"id":"GBJEHn7wB5Ba","executionInfo":{"status":"ok","timestamp":1692707467783,"user_tz":-540,"elapsed":9420,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"}},"outputId":"42dd32eb-b023-4518-daba-dbc92afcad5c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"elapsed":5962,"status":"ok","timestamp":1692707493088,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"o_SVy_MFfEjK","outputId":"fbefcc43-1144-4ad5-ba1d-acc0a3580b9d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>epoch_train_loss</td><td>0.66823</td></tr><tr><td>epoch_val_loss</td><td>0.62201</td></tr><tr><td>test_loss</td><td>0.61201</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230822_114826-t9z44fwe/logs</code>"]},"metadata":{}}],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"feQOyks8EluD"},"source":["# load trial"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":7880,"status":"ok","timestamp":1692707531506,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"Rco1sdgGXk3W","outputId":"06d58f61-db1a-4534-8d6d-56dc7ef523f7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.8"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230822_123203-t9z44fwe</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Resuming run <strong><a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"]},{"output_type":"execute_result","data":{"text/plain":["array(0.6107663, dtype=float32)"]},"metadata":{},"execution_count":49}],"source":["trial.wandb_load_run('t9z44fwe')\n","trial.load_model('rossi22/TRANS_VAE_SELFIES_TRAIN/TRANS_VAE_SELFIES_TRAIN_best_model_230822.pth:v0', from_wandb=True)\n","test_loss = trial.test(val_loader)\n","test_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334,"referenced_widgets":["29d0338ce52348849fab1f2982b2c724","089c892e81514f69830d53ccb5715afe","a931abcb1f4445658b7e2ccc0c2ba89f","3b337c3d14a14982b978fec68581a8a5","d8c5c6b77cba4fed946c4a48fa854a61","77bceb1fd2e14f0a8f75331720614019","001663b940f046afa1f5c173bfe98a58","e1d45533fc98471e95a02449256bc1dd"]},"executionInfo":{"elapsed":3580,"status":"ok","timestamp":1692707547795,"user":{"displayName":"Sungho Lim","userId":"03096434364214604940"},"user_tz":-540},"id":"BoLX19prWBxK","outputId":"333e430e-aa1e-4bf5-d265-b9e84a4b2ffe"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d0338ce52348849fab1f2982b2c724"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>epoch_train_loss</td><td>0.66823</td></tr><tr><td>epoch_val_loss</td><td>0.62201</td></tr><tr><td>test_loss</td><td>0.61077</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe' target=\"_blank\">https://wandb.ai/rossi22/TRANS_VAE_SELFIES_TRAIN/runs/t9z44fwe</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230822_123203-t9z44fwe/logs</code>"]},"metadata":{}}],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNcBeXBs8zq6wfPgBWq+/Qc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01dabf1d33dd43ff9d822a9882445e8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6120e24392f42e8bcba38183f3c043d","placeholder":"​","style":"IPY_MODEL_368ab894d8c0492cab9b313d2b2e1b28","value":"0.010 MB of 0.011 MB uploaded (0.000 MB deduped)\r"}},"08be7ac36f804c65bbc4aea49b24cd41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_452bba36c50a4aa7b1fbba879203a070","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3c3e96249bb47c786cea89ffe7eb2c3","value":1}},"144c71ea2af6406a87553d0b554e4716":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17105902b69e4c73b9f8307858d605f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"188e06db684942cf9ae1262857127558":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"368ab894d8c0492cab9b313d2b2e1b28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"452bba36c50a4aa7b1fbba879203a070":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87bae3b336914322b71ce2413cc8f45b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b1b2e58161554544bdee4d5c86284e69","IPY_MODEL_08be7ac36f804c65bbc4aea49b24cd41"],"layout":"IPY_MODEL_d4a66074d4484c449b6844115cbf3ea6"}},"a3c3e96249bb47c786cea89ffe7eb2c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1b2e58161554544bdee4d5c86284e69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3164a68fc3d4658ae998778bf961e27","placeholder":"​","style":"IPY_MODEL_cd3b5ad46dbf4e5d86c9bd7b1a9707f0","value":"0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"}},"bb1a2624dcb2492d84d6dd0006c8fe31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_188e06db684942cf9ae1262857127558","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17105902b69e4c73b9f8307858d605f2","value":0.8894188305953011}},"cd3b5ad46dbf4e5d86c9bd7b1a9707f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3164a68fc3d4658ae998778bf961e27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a66074d4484c449b6844115cbf3ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6120e24392f42e8bcba38183f3c043d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e03a21816d7b46e4a175e542b0bbd45a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_01dabf1d33dd43ff9d822a9882445e8e","IPY_MODEL_bb1a2624dcb2492d84d6dd0006c8fe31"],"layout":"IPY_MODEL_144c71ea2af6406a87553d0b554e4716"}},"29d0338ce52348849fab1f2982b2c724":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_089c892e81514f69830d53ccb5715afe","IPY_MODEL_a931abcb1f4445658b7e2ccc0c2ba89f"],"layout":"IPY_MODEL_3b337c3d14a14982b978fec68581a8a5"}},"089c892e81514f69830d53ccb5715afe":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8c5c6b77cba4fed946c4a48fa854a61","placeholder":"​","style":"IPY_MODEL_77bceb1fd2e14f0a8f75331720614019","value":"0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\r"}},"a931abcb1f4445658b7e2ccc0c2ba89f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_001663b940f046afa1f5c173bfe98a58","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1d45533fc98471e95a02449256bc1dd","value":0}},"3b337c3d14a14982b978fec68581a8a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8c5c6b77cba4fed946c4a48fa854a61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77bceb1fd2e14f0a8f75331720614019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"001663b940f046afa1f5c173bfe98a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1d45533fc98471e95a02449256bc1dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}